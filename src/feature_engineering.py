import pandas as pd
import numpy as np # For NaN representation if needed
# from ..src.config_models import FeatureEngineeringConfig # Example for type hinting
# from pydantic import validate_call # For validating inputs

# TODO: Define expected input/output schemas (e.g., using pandera or Pydantic models for rows)
#       Input: OHLCV data. Output: DataFrame with engineered features.

from ta.trend import (SMAIndicator, EMAIndicator, MACD, ADXIndicator, IchimokuIndicator,
                    PSARIndicator, VortexIndicator, TRIXIndicator, CCIIndicator,
                    KSTIndicator, CoppockCurve, DPOIndicator)
from ta.momentum import (RSIIndicator, StochasticOscillator, WilliamsRIndicator,
                       UltimateOscillator, AwesomeOscillatorIndicator, KAMAIndicator,
                       ROCIndicator, StochRSIIndicator, TSIIndicator, PercentagePriceOscillator) # Added TSI, PPO
from ta.volatility import (BollingerBands, AverageTrueRange, DonchianChannelIndicator, KeltnerChannel) # Added KeltnerChannel
from ta.volume import (OnBalanceVolumeIndicator, MoneyFlowIndexIndicator,
                     ChaikinMoneyFlowIndicator, ForceIndexIndicator, EaseOfMovementIndicator)

# Assuming src.data_management contains download_stock_data after rename
from src.data_management import download_stock_data # For example usage

def add_technical_indicators(data: pd.DataFrame, fillna: bool = False) -> pd.DataFrame: # Changed default fillna to False
    """
    Adds a comprehensive set of technical indicators to the stock data DataFrame.

    Args:
        data: A pandas DataFrame with stock data. 
              For multi-ticker data, expects 'Ticker' as the first level of a MultiIndex.
              Requires 'Open', 'High', 'Low', 'Close', 'Volume' columns.
              # TODO: Formalize input schema validation (e.g., check for required columns).
        fillna: If True, fills NaN values generated by indicators. 
                Default is False to leave NaNs for model preprocessing.
                # TODO: Consider if `fillna` strategy should be part of config.

    Returns:
        A pandas DataFrame with the added technical indicator columns.
        # TODO: Formalize output schema validation.
    """
    
    # TODO: Add try-except block for robust error handling during indicator calculation.
    # TODO: Log warnings for indicators that might produce all NaNs for certain inputs (e.g., short data series).

    # Determine if input is single or multi-ticker
    is_multi_ticker = isinstance(data.index, pd.MultiIndex)
    
    df_list_to_concat = []

    if not is_multi_ticker:
        # Process single ticker data
        df_processed = data.copy() # Use a copy to avoid modifying original DataFrame
        
        # TODO: Input validation: Check if df_processed contains required columns: 'Open', 'High', 'Low', 'Close', 'Volume'
        required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']
        if not all(col in df_processed.columns for col in required_cols):
            # TODO: Log this error or raise a custom exception
            print(f"Error: Missing one or more required columns for TA: {required_cols}")
            return data # Or None, or raise error, depending on desired fault tolerance

        # Apply indicators directly to df_processed
        df_processed['SMA_20'] = SMAIndicator(close=df_processed['Close'], window=20, fillna=fillna).sma_indicator()
        df_processed['EMA_20'] = EMAIndicator(close=df_processed['Close'], window=20, fillna=fillna).ema_indicator()
        df_processed['RSI_14'] = RSIIndicator(close=df_processed['Close'], window=14, fillna=fillna).rsi()
        macd = MACD(close=df_processed['Close'], fillna=fillna)
        df_processed['MACD'] = macd.macd()
        df_processed['MACD_signal'] = macd.macd_signal()
        df_processed['MACD_diff'] = macd.macd_diff()
        bb = BollingerBands(close=df_processed['Close'], window=20, window_dev=2, fillna=fillna)
        df_processed['BB_high'] = bb.bollinger_hband(); df_processed['BB_low'] = bb.bollinger_lband(); df_processed['BB_middle'] = bb.bollinger_mavg()
        df_processed['ATR_14'] = AverageTrueRange(high=df_processed['High'], low=df_processed['Low'], close=df_processed['Close'], window=14, fillna=fillna).average_true_range()
        dc = DonchianChannelIndicator(high=df_processed['High'], low=df_processed['Low'], close=df_processed['Close'], window=20, offset=0, fillna=fillna)
        df_processed['DC_high'] = dc.donchian_channel_hband(); df_processed['DC_low'] = dc.donchian_channel_lband(); df_processed['DC_middle'] = dc.donchian_channel_mband()
        stoch = StochasticOscillator(high=df_processed['High'], low=df_processed['Low'], close=df_processed['Close'], window=14, smooth_window=3, fillna=fillna)
        df_processed['Stoch_k'] = stoch.stoch(); df_processed['Stoch_d'] = stoch.stoch_signal()
        df_processed['WilliamsR_14'] = WilliamsRIndicator(high=df_processed['High'], low=df_processed['Low'], close=df_processed['Close'], lbp=14, fillna=fillna).williams_r()
        df_processed['Ultimate_Osc'] = UltimateOscillator(high=df_processed['High'], low=df_processed['Low'], close=df_processed['Close'], fillna=fillna).ultimate_oscillator()
        df_processed['Awesome_Osc'] = AwesomeOscillatorIndicator(high=df_processed['High'], low=df_processed['Low'], fillna=fillna).awesome_oscillator()
        df_processed['KAMA_10_2_30'] = KAMAIndicator(close=df_processed['Close'], window=10, pow1=2, pow2=30, fillna=fillna).kama()
        df_processed['ROC_12'] = ROCIndicator(close=df_processed['Close'], window=12, fillna=fillna).roc()
        stoch_rsi = StochRSIIndicator(close=df_processed['Close'], window=14, smooth1=3, smooth2=3, fillna=fillna)
        df_processed['StochRSI_k'] = stoch_rsi.stochrsi_k(); df_processed['StochRSI_d'] = stoch_rsi.stochrsi_d()
        df_processed['OBV'] = OnBalanceVolumeIndicator(close=df_processed['Close'], volume=df_processed['Volume'], fillna=fillna).on_balance_volume()
        df_processed['MFI_14'] = MoneyFlowIndexIndicator(high=df_processed['High'], low=df_processed['Low'], close=df_processed['Close'], volume=df_processed['Volume'], window=14, fillna=fillna).money_flow_index()
        df_processed['CMF_20'] = ChaikinMoneyFlowIndicator(high=df_processed['High'], low=df_processed['Low'], close=df_processed['Close'], volume=df_processed['Volume'], window=20, fillna=fillna).chaikin_money_flow()
        df_processed['ForceIdx_13'] = ForceIndexIndicator(close=df_processed['Close'], volume=df_processed['Volume'], window=13, fillna=fillna).force_index()
        df_processed['EOM_14'] = EaseOfMovementIndicator(high=df_processed['High'], low=df_processed['Low'], volume=df_processed['Volume'], window=14, fillna=fillna).ease_of_movement()
        adx_indicator = ADXIndicator(high=df_processed['High'], low=df_processed['Low'], close=df_processed['Close'], window=14, fillna=fillna)
        df_processed['ADX_14'] = adx_indicator.adx(); df_processed['ADX_pos_14'] = adx_indicator.adx_pos(); df_processed['ADX_neg_14'] = adx_indicator.adx_neg()
        ichimoku = IchimokuIndicator(high=df_processed['High'], low=df_processed['Low'], window1=9, window2=26, window3=52, visual=False, fillna=fillna)
        df_processed['Ichimoku_A'] = ichimoku.ichimoku_a(); df_processed['Ichimoku_B'] = ichimoku.ichimoku_b()
        df_processed['Ichimoku_Kijun'] = ichimoku.ichimoku_kijun_sen(); df_processed['Ichimoku_Tenkan'] = ichimoku.ichimoku_tenkan_sen()
        psar = PSARIndicator(high=df_processed['High'], low=df_processed['Low'], close=df_processed['Close'], fillna=fillna)
        df_processed['PSAR_up'] = psar.psar_up(); df_processed['PSAR_down'] = psar.psar_down()
        vortex = VortexIndicator(high=df_processed['High'], low=df_processed['Low'], close=df_processed['Close'], window=14, fillna=fillna)
        df_processed['Vortex_pos_14'] = vortex.vortex_indicator_pos(); df_processed['Vortex_neg_14'] = vortex.vortex_indicator_neg()
        df_processed['TRIX_15'] = TRIXIndicator(close=df_processed['Close'], window=15, fillna=fillna).trix()
        df_processed['CCI_20'] = CCIIndicator(high=df_processed['High'], low=df_processed['Low'], close=df_processed['Close'], window=20, constant=0.015, fillna=fillna).cci()
        kst = KSTIndicator(close=df_processed['Close'], fillna=fillna)
        df_processed['KST'] = kst.kst(); df_processed['KST_sig'] = kst.kst_sig()
        df_processed['Coppock_10_11_14'] = CoppockCurve(close=df_processed['Close'],wma_window=10, roc1_window=11, roc2_window=14, fillna=fillna).coppock()
        df_processed['DPO_20'] = DPOIndicator(close=df_processed['Close'], window=20, fillna=fillna).dpo()

        # New Indicators
        kc = KeltnerChannel(high=df_processed['High'], low=df_processed['Low'], close=df_processed['Close'], window=20, window_atr=10, fillna=fillna)
        df_processed['KC_high'] = kc.keltner_channel_hband(); df_processed['KC_low'] = kc.keltner_channel_lband(); df_processed['KC_middle'] = kc.keltner_channel_mband()
        df_processed['TSI'] = TSIIndicator(close=df_processed['Close'], window_slow=25, window_fast=13, fillna=fillna).tsi()
        ppo = PercentagePriceOscillator(close=df_processed['Close'], window_slow=26, window_fast=12, window_sign=9, fillna=fillna)
        df_processed['PPO'] = ppo.ppo(); df_processed['PPO_signal'] = ppo.ppo_signal(); df_processed['PPO_hist'] = ppo.ppo_hist()
        
        df_list_to_concat.append(df_processed) # Add the single processed DataFrame to the list

    else: # Multi-ticker DataFrame
        for ticker, group_data in data.groupby(level='Ticker'):
            df_group = group_data.copy()
            # Need to reset index to apply indicators if 'Ticker' is part of index, then set it back
            # Or, ensure that ta library functions can handle MultiIndex (some might, some might not directly)
            # The current structure assumes that functions are applied to a simple DataFrame (group_data)
            
            # --- Apply indicators to df_group ---
            # Existing indicators (ensure fillna is used)
            df_group['SMA_20'] = SMAIndicator(close=df_group['Close'], window=20, fillna=fillna).sma_indicator()
            df_group['EMA_20'] = EMAIndicator(close=df_group['Close'], window=20, fillna=fillna).ema_indicator()
            df_group['RSI_14'] = RSIIndicator(close=df_group['Close'], window=14, fillna=fillna).rsi()
            macd = MACD(close=df_group['Close'], fillna=fillna)
            df_group['MACD'] = macd.macd(); df_group['MACD_signal'] = macd.macd_signal(); df_group['MACD_diff'] = macd.macd_diff()
            bb = BollingerBands(close=df_group['Close'], window=20, window_dev=2, fillna=fillna)
            df_group['BB_high'] = bb.bollinger_hband(); df_group['BB_low'] = bb.bollinger_lband(); df_group['BB_middle'] = bb.bollinger_mavg()
            df_group['ATR_14'] = AverageTrueRange(high=df_group['High'], low=df_group['Low'], close=df_group['Close'], window=14, fillna=fillna).average_true_range()
            dc = DonchianChannelIndicator(high=df_group['High'], low=df_group['Low'], close=df_group['Close'], window=20, offset=0, fillna=fillna)
            df_group['DC_high'] = dc.donchian_channel_hband(); df_group['DC_low'] = dc.donchian_channel_lband(); df_group['DC_middle'] = dc.donchian_channel_mband()
            stoch = StochasticOscillator(high=df_group['High'], low=df_group['Low'], close=df_group['Close'], window=14, smooth_window=3, fillna=fillna)
            df_group['Stoch_k'] = stoch.stoch(); df_group['Stoch_d'] = stoch.stoch_signal()
            df_group['WilliamsR_14'] = WilliamsRIndicator(high=df_group['High'], low=df_group['Low'], close=df_group['Close'], lbp=14, fillna=fillna).williams_r()
            df_group['Ultimate_Osc'] = UltimateOscillator(high=df_group['High'], low=df_group['Low'], close=df_group['Close'], fillna=fillna).ultimate_oscillator()
            df_group['Awesome_Osc'] = AwesomeOscillatorIndicator(high=df_group['High'], low=df_group['Low'], fillna=fillna).awesome_oscillator()
            df_group['KAMA_10_2_30'] = KAMAIndicator(close=df_group['Close'], window=10, pow1=2, pow2=30, fillna=fillna).kama()
            df_group['ROC_12'] = ROCIndicator(close=df_group['Close'], window=12, fillna=fillna).roc()
            stoch_rsi = StochRSIIndicator(close=df_group['Close'], window=14, smooth1=3, smooth2=3, fillna=fillna)
            df_group['StochRSI_k'] = stoch_rsi.stochrsi_k(); df_group['StochRSI_d'] = stoch_rsi.stochrsi_d()
            df_group['OBV'] = OnBalanceVolumeIndicator(close=df_group['Close'], volume=df_group['Volume'], fillna=fillna).on_balance_volume()
            df_group['MFI_14'] = MoneyFlowIndexIndicator(high=df_group['High'], low=df_group['Low'], close=df_group['Close'], volume=df_group['Volume'], window=14, fillna=fillna).money_flow_index()
            df_group['CMF_20'] = ChaikinMoneyFlowIndicator(high=df_group['High'], low=df_group['Low'], close=df_group['Close'], volume=df_group['Volume'], window=20, fillna=fillna).chaikin_money_flow()
            df_group['ForceIdx_13'] = ForceIndexIndicator(close=df_group['Close'], volume=df_group['Volume'], window=13, fillna=fillna).force_index()
            df_group['EOM_14'] = EaseOfMovementIndicator(high=df_group['High'], low=df_group['Low'], volume=df_group['Volume'], window=14, fillna=fillna).ease_of_movement()
            adx_indicator = ADXIndicator(high=df_group['High'], low=df_group['Low'], close=df_group['Close'], window=14, fillna=fillna)
            df_group['ADX_14'] = adx_indicator.adx(); df_group['ADX_pos_14'] = adx_indicator.adx_pos(); df_group['ADX_neg_14'] = adx_indicator.adx_neg()
            ichimoku = IchimokuIndicator(high=df_group['High'], low=df_group['Low'], window1=9, window2=26, window3=52, visual=False, fillna=fillna)
            df_group['Ichimoku_A'] = ichimoku.ichimoku_a(); df_group['Ichimoku_B'] = ichimoku.ichimoku_b()
            df_group['Ichimoku_Kijun'] = ichimoku.ichimoku_kijun_sen(); df_group['Ichimoku_Tenkan'] = ichimoku.ichimoku_tenkan_sen()
            psar = PSARIndicator(high=df_group['High'], low=df_group['Low'], close=df_group['Close'], fillna=fillna)
            df_group['PSAR_up'] = psar.psar_up(); df_group['PSAR_down'] = psar.psar_down()
            vortex = VortexIndicator(high=df_group['High'], low=df_group['Low'], close=df_group['Close'], window=14, fillna=fillna)
            df_group['Vortex_pos_14'] = vortex.vortex_indicator_pos(); df_group['Vortex_neg_14'] = vortex.vortex_indicator_neg()
            df_group['TRIX_15'] = TRIXIndicator(close=df_group['Close'], window=15, fillna=fillna).trix()
            df_group['CCI_20'] = CCIIndicator(high=df_group['High'], low=df_group['Low'], close=df_group['Close'], window=20, constant=0.015, fillna=fillna).cci()
            kst = KSTIndicator(close=df_group['Close'], fillna=fillna)
            df_group['KST'] = kst.kst(); df_group['KST_sig'] = kst.kst_sig()
            df_group['Coppock_10_11_14'] = CoppockCurve(close=df_group['Close'],wma_window=10, roc1_window=11, roc2_window=14, fillna=fillna).coppock()
            df_group['DPO_20'] = DPOIndicator(close=df_group['Close'], window=20, fillna=fillna).dpo()

            # New Indicators
            kc = KeltnerChannel(high=df_group['High'], low=df_group['Low'], close=df_group['Close'], window=20, window_atr=10, fillna=fillna)
            df_group['KC_high'] = kc.keltner_channel_hband(); df_group['KC_low'] = kc.keltner_channel_lband(); df_group['KC_middle'] = kc.keltner_channel_mband()
            df_group['TSI'] = TSIIndicator(close=df_group['Close'], window_slow=25, window_fast=13, fillna=fillna).tsi()
            ppo = PercentagePriceOscillator(close=df_group['Close'], window_slow=26, window_fast=12, window_sign=9, fillna=fillna)
            df_group['PPO'] = ppo.ppo(); df_group['PPO_signal'] = ppo.ppo_signal(); df_group['PPO_hist'] = ppo.ppo_hist()
            
            df_list_to_concat.append(df_group)

    # Concatenate all processed groups (or the single processed df)
    final_df_with_indicators = pd.concat(df_list_to_concat)
    
        # If it was a single ticker and we wrapped it earlier (current logic doesn't wrap for single path), adjust back.
        # The current single-ticker path processes directly, so no unwrapping needed here.
        pass

    # TODO: Save schema/metadata of the feature-engineered DataFrame if it's an intermediate artifact.
    #       E.g., if config.output_path is provided:
    #       final_df_with_indicators.to_parquet(config.output_path)
    #       generate_and_save_schema(final_df_with_indicators, config.output_path + ".schema.json")
    
    # TODO: Ensure feature names are consistent and don't clash if this function is called multiple times or with other feature functions.
    #       Consider prefixing, or ensuring input `data` doesn't already have these columns.
    return final_df_with_indicators


def add_rolling_lag_features(data: pd.DataFrame, windows: list[int] = None, lags: list[int] = None, 
                              lag_indicators: list[str] = None
                              # config: Optional[FeatureEngineeringConfig] = None # Alternative for passing params
                              ) -> pd.DataFrame:
    """
    Adds rolling window statistics and lagged features to the DataFrame.

    Args:
        data: Input DataFrame with OHLCV and potentially other features.
              # TODO: Formalize input schema validation.
        windows: List of window sizes for rolling statistics.
        lags: List of lag periods for lagged features.
        lag_indicators: List of column names for which to create lagged versions.
              # TODO: Ensure these columns exist in `data` before trying to lag them.

    Returns:
        DataFrame with added rolling and lag features.
        # TODO: Formalize output schema validation.
    """
    if windows is None: windows = [5, 10, 20]
    if lags is None: lags = [1, 2, 3, 5]
    # Default lag_indicators should ideally be chosen carefully, e.g., from config or based on available columns.
    if lag_indicators is None: lag_indicators = ['RSI_14', 'MACD'] 
    
    # TODO: Add try-except for robustness.
    # TODO: Consider caching results of this computation if `data` and parameters are unchanged.

    df_featured = data.copy()
    is_multi_ticker = isinstance(df_featured.index, pd.MultiIndex)

    if not is_multi_ticker:
        # Process as single ticker
        df_processed_single = df_featured # Operate on the copy
        # TODO: Input validation: Check for 'Close' and columns in `lag_indicators`.
        for window in windows:
            df_processed_single[f'Close_rol_mean_{window}'] = df_processed_single['Close'].rolling(window=window, min_periods=1).mean()
            df_processed_single[f'Close_rol_std_{window}'] = df_processed_single['Close'].rolling(window=window, min_periods=1).std()
            if 'Volume' in df_processed_single.columns:
                 df_processed_single[f'Volume_rol_mean_{window}'] = df_processed_single['Volume'].rolling(window=window, min_periods=1).mean()
        for lag in lags:
            df_processed_single[f'Close_lag_{lag}'] = df_processed_single['Close'].shift(lag)
            for indicator_col in lag_indicators:
                if indicator_col in df_processed_single.columns:
                    df_processed_single[f'{indicator_col}_lag_{lag}'] = df_processed_single[indicator_col].shift(lag)
        return df_processed_single
    else:
        # Multi-ticker DataFrame
        processed_groups = []
        for ticker, group_data in df_featured.groupby(level='Ticker'):
            group_copy = group_data.copy()
            for window in windows:
                group_copy[f'Close_rol_mean_{window}'] = group_copy['Close'].rolling(window=window, min_periods=1).mean()
                group_copy[f'Close_rol_std_{window}'] = group_copy['Close'].rolling(window=window, min_periods=1).std()
                if 'Volume' in group_copy.columns:
                    group_copy[f'Volume_rol_mean_{window}'] = group_copy['Volume'].rolling(window=window, min_periods=1).mean()
            for lag in lags:
                group_copy[f'Close_lag_{lag}'] = group_copy['Close'].shift(lag)
                for indicator_col in lag_indicators:
                    if indicator_col in group_copy.columns:
                         group_copy[f'{indicator_col}_lag_{lag}'] = group_copy[indicator_col].shift(lag)
            processed_groups.append(group_copy)
        return pd.concat(processed_groups)
        
def create_target_variable(df: pd.DataFrame, future_days: int, percent_change_threshold: float) -> pd.DataFrame:
    data_with_target = df.copy()
    is_multi_ticker = isinstance(data_with_target.index, pd.MultiIndex)

    if not is_multi_ticker:
        df_single_target = data_with_target
        df_single_target['future_close'] = df_single_target['Close'].shift(-future_days)
        df_single_target['price_change_pct'] = (df_single_target['future_close'] - df_single_target['Close']) / df_single_target['Close']
        
        # Define target: 1 if price change meets threshold (up or down), 0 otherwise.
        # This definition implies a volatility prediction or significant move prediction.
        # For directional prediction (long/short), one might use different labels (e.g., 1 for up, -1 for down, 0 for neutral).
        # The current definition makes it a binary classification for "significant move expected".
        df_single_target['target'] = 0 
        df_single_target.loc[df_single_target['price_change_pct'].abs() > percent_change_threshold, 'target'] = 1
        # Example for directional target:
        # df_single_target['target_direction'] = 0
        # df_single_target.loc[df_single_target['price_change_pct'] > percent_change_threshold, 'target_direction'] = 1  # Up
        # df_single_target.loc[df_single_target['price_change_pct'] < -percent_change_threshold, 'target_direction'] = 2 # Down (or -1 if preferred)

        df_single_target.drop(columns=['future_close', 'price_change_pct'], inplace=True)
        # TODO: Ensure 'target' column name is consistent with what modeling step expects (e.g., from config).
        return df_single_target
    else: # Multi-ticker
        all_tickers_target = []
        for ticker, group_data in data_with_target.groupby(level='Ticker'):
            group_copy = group_data.copy()
            group_copy['future_close'] = group_copy['Close'].shift(-future_days)
            group_copy['price_change_pct'] = (group_copy['future_close'] - group_copy['Close']) / group_copy['Close']
            group_copy['target'] = 0
            group_copy.loc[group_copy['price_change_pct'].abs() > percent_change_threshold, 'target'] = 1
            group_copy.drop(columns=['future_close', 'price_change_pct'], inplace=True)
            all_tickers_target.append(group_copy)
        return pd.concat(all_tickers_target)

# TODO: Add a master function to orchestrate all feature engineering steps based on a config object.
# def generate_all_features(config: FeatureEngineeringConfig) -> pd.DataFrame | None:
#     # 1. Load data using config.input_data_path
#     #    raw_df = load_validated_data(config.input_data_path, expected_raw_schema)
#     #    if raw_df is None: return None
# 
#     # 2. Apply technical indicators if config.technical_indicators_enabled
#     #    df_with_ti = add_technical_indicators(raw_df, config.technical_indicator_params)
# 
#     # 3. Add rolling/lag features if config.rolling_lag_enabled
#     #    df_with_roll_lag = add_rolling_lag_features(df_with_ti, config.rolling_params, config.lag_params)
# 
#     # 4. Add sentiment features (details depend on sentiment_analysis module)
#     #    if config.sentiment_features_enabled:
#     #        df_with_sentiment = add_sentiment_scores(df_with_roll_lag, config.sentiment_config)
# 
#     # 5. Add fundamental features (details depend on fundamental_data module)
#     #    if config.fundamental_features_enabled:
#     #        df_with_fundamentals = add_fundamental_data(df_with_sentiment, config.fundamental_config)
# 
#     # 6. Create target variable if config.target_variable_enabled
#     #    final_df = create_target_variable(df_with_fundamentals, config.target_config)
# 
#     # 7. Select final feature set if config.feature_list_to_use is specified
#     #    final_df = final_df[config.feature_list_to_use + [config.target_column_name]]
# 
#     # 8. Save processed features and schema/metadata
#     #    save_validated_data(final_df, config.output_features_path, final_schema)
#     #    save_feature_engineering_metadata(config, feature_stats, output_metadata_path)
# 
#     # return final_df
#     pass


if __name__ == '__main__':
    tickers_example = ['AAPL'] # Using single ticker for simplicity in example output
    start_date_example = '2023-01-01'
    end_date_example = '2023-03-31' 

    raw_data_example = download_stock_data(tickers_example, start_date_example, end_date_example)

    if raw_data_example is not None:
        # If download_stock_data for single ticker returns MultiIndex columns, drop 'Ticker' level for feature engineering
        # The current download_stock_data in data_management.py should return a simple DataFrame for single ticker.
        # If it's multi-indexed for a single ticker, this handles it:
        data_to_process = raw_data_example
        if isinstance(raw_data_example.columns, pd.MultiIndex) and len(raw_data_example.columns.levels[0]) == 1:
             data_to_process = raw_data_example.droplevel(0, axis=1)
        
        print(f"--- Original Data ({tickers_example[0]}) ---")
        print(data_to_process.head())

        # Test with fillna=False (new default)
        data_with_ti = add_technical_indicators(data_to_process.copy(), fillna=False)
        print(f"\n--- Data with Technical Indicators (fillna=False) ({tickers_example[0]}) ---")
        print(f"Number of columns after adding TIs: {len(data_with_ti.columns)}")
        
        # Check some of the newly added indicators and a few old ones
        new_indicator_cols = ['KC_middle', 'TSI', 'PPO']
        existing_cols_to_check = ['ADX_14', 'Ichimoku_A', 'WilliamsR_14']
        cols_to_print = new_indicator_cols + existing_cols_to_check
        # Ensure columns exist before trying to print, in case any failed (e.g. due to short data window)
        valid_cols_to_print = [col for col in cols_to_print if col in data_with_ti.columns]
        print(f"Sample of selected indicators (first 5 rows, last 5 rows to see NaNs):\n{data_with_ti[valid_cols_to_print].head(5)}")
        print(f"{data_with_ti[valid_cols_to_print].tail(5)}")
        
        key_lag_indicators = ['RSI_14', 'MACD', 'ATR_14', 'KC_middle', 'TSI', 'PPO'] 
        data_with_roll_lag = add_rolling_lag_features(
            data_with_ti.copy(), 
            windows=[5, 10], lags=[1, 2],
            lag_indicators=key_lag_indicators
        )
        print(f"\n--- Data with Rolling/Lag Features ({tickers_example[0]}) ---")
        print(f"Number of columns after adding rolling/lag: {len(data_with_roll_lag.columns)}")
        # Check a few rolling/lag features including one for a new indicator
        roll_lag_cols_to_print = [col for col in data_with_roll_lag.columns if 'rol_mean' in col or '_lag_1' in col]
        valid_roll_lag_cols = [col for col in roll_lag_cols_to_print if col in data_with_roll_lag.columns][:5] # Print up to 5
        print(f"Sample of selected rolling/lag features:\n{data_with_roll_lag[valid_roll_lag_cols].tail(10)}")
        
    else:
        print("Failed to download example data.")
