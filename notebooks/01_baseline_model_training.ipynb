{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline XGBoost Model Training for Stock Price Movement Prediction\n",
    "\n",
    "This notebook demonstrates a baseline workflow for training an XGBoost model to predict significant stock price movements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src directory to Python path to import custom modules\n",
    "module_path = os.path.abspath(os.path.join('..')) # Assumes notebook is in 'notebooks' directory\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.data_management import download_stock_data # Corrected import from data_management\n",
    "from src.feature_engineering import add_technical_indicators, add_rolling_lag_features, create_target_variable\n",
    "from src.backtesting import run_backtrader_backtest # Corrected import for backtrader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TICKER = 'AAPL' # Example ticker\n",
    "START_DATE = '2019-01-01' # Extended start date for more data for rolling/lag features\n",
    "END_DATE = '2023-12-31'\n",
    "INTERVAL = '1d'\n",
    "\n",
    "FUTURE_DAYS_TARGET = 5      # X days for target variable definition\n",
    "PERCENT_CHANGE_THRESHOLD = 0.03 # Y% change for target variable definition\n",
    "\n",
    "ROLLING_WINDOWS = [5, 10, 20, 60]\n",
    "LAG_PERIODS = [1, 2, 3, 5, 10]\n",
    "KEY_LAG_INDICATORS = ['RSI_14', 'MACD', 'ATR_14', 'Stoch_k', 'ADX_14'] \n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_download = download_stock_data([TICKER], START_DATE, END_DATE, INTERVAL)\n",
    "if raw_data_download is not None:\n",
    "    print(f\"Downloaded data for {TICKER}:\")\n",
    "    # For single ticker, yfinance might return data without 'Ticker' level if not passed as list\n",
    "    # Our download_stock_data ensures it's a list, so 'Ticker' level should be present.\n",
    "    # If it was downloaded for a single ticker and Ticker level is missing, we might need to adjust here.\n",
    "    # However, our current download_stock_data returns a DataFrame where columns are price types if single ticker,\n",
    "    # or MultiIndex columns if multiple tickers. Let's assume it's processed correctly by downstream.\n",
    "    # For Backtrader, we need OHLCV directly. If single ticker, yf output is already like that.\n",
    "    # The `processed_data` later will be sliced for `ohlc_test` which should be fine.\n",
    "    # Make sure `raw_data` for single ticker has 'Volume' for feature engineering.\n",
    "    if isinstance(raw_data_download.columns, pd.MultiIndex):\n",
    "        raw_data = raw_data_download.droplevel(0, axis=1) # Drop 'Ticker' level from columns if present\n",
    "    else:\n",
    "        raw_data = raw_data_download\n",
    "    print(raw_data.head())\n",
    "    print(f\"Shape of raw data: {raw_data.shape}\")\n",
    "else:\n",
    "    raise SystemExit(f\"Failed to download data for {TICKER}. Halting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Add Technical Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_ti = add_technical_indicators(raw_data.copy(), fillna=True)\n",
    "print(f\"Shape after TIs: {data_with_ti.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Add Rolling and Lag Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_roll_lag = add_rolling_lag_features(\n",
    "    data_with_ti.copy(),\n",
    "    windows=ROLLING_WINDOWS,\n",
    "    lags=LAG_PERIODS,\n",
    "    lag_indicators=KEY_LAG_INDICATORS\n",
    ")\n",
    "print(f\"Shape after rolling/lag: {data_with_roll_lag.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Create Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_full = create_target_variable(\n",
    "    data_with_roll_lag.copy(), \n",
    "    future_days=FUTURE_DAYS_TARGET, \n",
    "    percent_change_threshold=PERCENT_CHANGE_THRESHOLD\n",
    ")\n",
    "print(f\"Shape after target: {processed_data_full.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Preprocessing for Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Select Features (X) and Target (y), Handle NaNs, Prepare OHLCV for Backtrader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_price_volume_cols = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
    "feature_columns = [col for col in processed_data_full.columns if col not in base_price_volume_cols + ['target']]\n",
    "\n",
    "X_uncleaned = processed_data_full[feature_columns]\n",
    "y_uncleaned = processed_data_full['target']\n",
    "# For backtrader, we need OHLCV. Ensure 'Volume' is present. 'OpenInterest' will be dummied by backtester if not present.\n",
    "ohlcv_uncleaned = processed_data_full[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
    "\n",
    "# Combine features and target for consistent NaN dropping based on model inputs\n",
    "model_input_df = X_uncleaned.assign(target=y_uncleaned)\n",
    "cleaned_indices = model_input_df.dropna().index\n",
    "\n",
    "X_cleaned = X_uncleaned.loc[cleaned_indices]\n",
    "y_cleaned = y_uncleaned.loc[cleaned_indices]\n",
    "ohlcv_cleaned = ohlcv_uncleaned.loc[cleaned_indices] # Align OHLCV data with cleaned features/target\n",
    "\n",
    "print(f\"Shape after NaN drop: X: {X_cleaned.shape}, y: {y_cleaned.shape}, OHLCV: {ohlcv_cleaned.shape}\")\n",
    "if X_cleaned.empty:\n",
    "    raise SystemExit(\"No data left after NaN removal for model training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Split Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, ohlcv_train, ohlcv_test = train_test_split(\n",
    "    X_cleaned, y_cleaned, ohlcv_cleaned,\n",
    "    test_size=TEST_SIZE, \n",
    "    shuffle=False, \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "print(f\"Test set shape: X_test: {X_test.shape}, ohlcv_test: {ohlcv_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train XGBoost Model (as before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(objective='binary:logistic', n_estimators=100, learning_rate=0.1, max_depth=3, use_label_encoder=False, eval_metric='logloss')\n",
    "model.fit(X_train, y_train)\n",
    "print(\"XGBoost model trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Make Predictions (as before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model.predict(X_test)\n",
    "y_pred_proba_test = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate Model (as before, shortened output for brevity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_test):.4f}\")\n",
    "print(classification_report(y_test, y_pred_test, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Importance (as before, shortened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass # Feature importance plotting omitted for this refactoring focus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Backtesting with `run_backtrader_backtest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare signals for Backtrader: needs to be a Series with name 'signal'\n",
    "# The 'perfect foresight' signal generation from previous notebook version:\n",
    "signals_for_bt = pd.Series(0, index=X_test.index, name='signal', dtype=int)\n",
    "y_pred_series_test = pd.Series(y_pred_test, index=X_test.index)\n",
    "\n",
    "for date_idx, model_pred_signal_val in y_pred_series_test.items():\n",
    "    if model_pred_signal_val == 1: # If model predicts significant move\n",
    "        # Use processed_data_full to get the actual future price for direction\n",
    "        # Ensure date_idx is valid in processed_data_full\n",
    "        if date_idx not in processed_data_full.index: continue\n",
    "        current_price = processed_data_full['Close'].loc[date_idx]\n",
    "        try:\n",
    "            current_date_loc = processed_data_full.index.get_loc(date_idx)\n",
    "            future_date_loc = current_date_loc + FUTURE_DAYS_TARGET\n",
    "            if future_date_loc < len(processed_data_full.index):\n",
    "                future_price_idx = processed_data_full.index[future_date_loc]\n",
    "                future_price = processed_data_full['Close'].loc[future_price_idx]\n",
    "                if future_price > current_price: signals_for_bt.loc[date_idx] = 1\n",
    "                elif future_price < current_price: signals_for_bt.loc[date_idx] = -1\n",
    "        except Exception as e:\n",
    "            print(f\"Signal generation error for {date_idx}: {e}\")\n",
    "\n",
    "print(\"\\nValue counts for 'perfect foresight' signals for Backtrader:\")\n",
    "print(signals_for_bt.value_counts())\n",
    "\n",
    "# Ensure ohlcv_test has 'Volume'. yfinance data usually includes it.\n",
    "if 'Volume' not in ohlcv_test.columns:\n",
    "    print(\"Warning: 'Volume' not in ohlcv_test. Adding dummy volume for Backtrader.\")\n",
    "    ohlcv_test_bt = ohlcv_test.assign(Volume=100000) # Add dummy volume\n",
    "else:\n",
    "    ohlcv_test_bt = ohlcv_test.copy()\n",
    "\n",
    "initial_capital_bt = 100000.0\n",
    "\n",
    "print(\"\\n--- Backtrader Scenario 1: Baseline (Leverage 1x, Comm 2bps, Slip 1bps) ---\")\n",
    "metrics1_bt, cerebro1_bt = run_backtrader_backtest(\n",
    "    data_df=ohlcv_test_bt, \n",
    "    signals_df=signals_for_bt, \n",
    "    initial_capital=initial_capital_bt,\n",
    "    leverage=1.0,\n",
    "    commission_bps=2.0,\n",
    "    slippage_bps=1.0\n",
    ")\n",
    "for metric, value in metrics1_bt.items(): print(f\"  {metric}: {value}\")\n",
    "\n",
    "print(\"\\n--- Backtrader Scenario 2: Higher Leverage (2x) ---\")\n",
    "metrics2_bt, cerebro2_bt = run_backtrader_backtest(\n",
    "    data_df=ohlcv_test_bt, \n",
    "    signals_df=signals_for_bt, \n",
    "    initial_capital=initial_capital_bt,\n",
    "    leverage=2.0, # Increased leverage\n",
    "    commission_bps=2.0,\n",
    "    slippage_bps=1.0\n",
    ")\n",
    "for metric, value in metrics2_bt.items(): print(f\"  {metric}: {value}\")\n",
    "\n",
    "print(\"\\n--- Backtrader Scenario 3: Higher Costs (Comm 5bps, Slip 3bps) ---\")\n",
    "metrics3_bt, cerebro3_bt = run_backtrader_backtest(\n",
    "    data_df=ohlcv_test_bt, \n",
    "    signals_df=signals_for_bt, \n",
    "    initial_capital=initial_capital_bt,\n",
    "    leverage=1.0,\n",
    "    commission_bps=5.0, # Increased commission\n",
    "    slippage_bps=3.0    # Increased slippage\n",
    ")\n",
    "for metric, value in metrics3_bt.items(): print(f\"  {metric}: {value}\")\n",
    "\n",
    "print(\"\\nNote: Knock-out parameters are placeholders in run_backtrader_backtest and not yet implemented.\")\n",
    "\n",
    "# Optional: Plotting (might require specific setup for notebook environment)\n",
    "try:\n",
    "    print(\"\\nAttempting to plot results for Scenario 1 (Baseline)... NOTE: Plotting may not render in all remote environments.\")\n",
    "    # cerebro1_bt.plot(style='candlestick', barup='green', bardown='red') # This would generate a plot window\n",
    "    # For saving to file or showing inline, more setup might be needed depending on environment.\n",
    "    # For now, we'll just acknowledge it ran.\n",
    "    print(\"Plot command executed (actual display depends on environment).\")\n",
    "except Exception as e:\n",
    "    print(f\"Cerebro plotting failed: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
