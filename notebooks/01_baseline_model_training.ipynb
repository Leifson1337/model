{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline XGBoost Model Training for Stock Price Movement Prediction\n",
    "\n",
    "This notebook demonstrates a baseline workflow for training an XGBoost model to predict significant stock price movements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src directory to Python path to import custom modules\n",
    "module_path = os.path.abspath(os.path.join('..')) # Assumes notebook is in 'notebooks' directory\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.data_loader import download_stock_data\n",
    "from src.feature_engineering import add_technical_indicators, add_rolling_lag_features, create_target_variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TICKER = 'AAPL' # Example ticker\n",
    "START_DATE = '2019-01-01' # Extended start date for more data for rolling/lag features\n",
    "END_DATE = '2023-12-31'\n",
    "INTERVAL = '1d'\n",
    "\n",
    "FUTURE_DAYS_TARGET = 5      # X days for target variable definition\n",
    "PERCENT_CHANGE_THRESHOLD = 0.03 # Y% change for target variable definition\n",
    "\n",
    "# Rolling/Lag feature parameters (can be adjusted)\n",
    "ROLLING_WINDOWS = [5, 10, 20, 60]\n",
    "LAG_PERIODS = [1, 2, 3, 5, 10]\n",
    "KEY_LAG_INDICATORS = ['RSI_14', 'MACD', 'ATR_14', 'Stoch_k', 'ADX_14'] # Selected key indicators to lag\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42 # For reproducibility of train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = download_stock_data([TICKER], START_DATE, END_DATE, INTERVAL)\n",
    "if raw_data is not None:\n",
    "    print(f\"Downloaded data for {TICKER}:\")\n",
    "    print(raw_data.head())\n",
    "    print(f\"Shape of raw data: {raw_data.shape}\")\n",
    "else:\n",
    "    print(f\"Failed to download data for {TICKER}.\")\n",
    "    # Handle error appropriately, e.g., by exiting or using sample data\n",
    "    # For this notebook, we'll assume data download is successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Add Technical Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if raw_data is not None:\n",
    "    data_with_ti = add_technical_indicators(raw_data.copy(), fillna=True) # fillna=True is important\n",
    "    print(\"\\nData with Technical Indicators:\")\n",
    "    print(data_with_ti.head())\n",
    "    print(f\"Shape after adding technical indicators: {data_with_ti.shape}\")\n",
    "    # print(data_with_ti.columns.tolist()) # To see all new TI columns\n",
    "else:\n",
    "    print(\"Skipping technical indicators as raw_data is None.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Add Rolling and Lag Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'data_with_ti' in locals() and data_with_ti is not None:\n",
    "    data_with_roll_lag = add_rolling_lag_features(\n",
    "        data_with_ti.copy(),\n",
    "        windows=ROLLING_WINDOWS,\n",
    "        lags=LAG_PERIODS,\n",
    "        lag_indicators=KEY_LAG_INDICATORS\n",
    "    )\n",
    "    print(\"\\nData with Rolling and Lag Features:\")\n",
    "    print(data_with_roll_lag.head())\n",
    "    print(f\"Shape after adding rolling/lag features: {data_with_roll_lag.shape}\")\n",
    "    # print(data_with_roll_lag.columns.tolist())\n",
    "else:\n",
    "    print(\"Skipping rolling/lag features as data_with_ti is not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Create Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'data_with_roll_lag' in locals() and data_with_roll_lag is not None:\n",
    "    processed_data = create_target_variable(\n",
    "        data_with_roll_lag.copy(), \n",
    "        future_days=FUTURE_DAYS_TARGET, \n",
    "        percent_change_threshold=PERCENT_CHANGE_THRESHOLD\n",
    "    )\n",
    "    print(\"\\nData with Target Variable:\")\n",
    "    print(processed_data.head())\n",
    "    print(f\"Shape after adding target variable: {processed_data.shape}\")\n",
    "    # Display some rows where target might be 1\n",
    "    # print(processed_data[processed_data['target'] == 1].head())\n",
    "else:\n",
    "    print(\"Skipping target variable creation as data_with_roll_lag is not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Preprocessing for Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Select Features (X) and Target (y), Drop NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'processed_data' in locals() and processed_data is not None:\n",
    "    # Features: all columns except 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume' (original price data) and 'target'.\n",
    "    # This means we use all technical indicators, rolling features, and lag features.\n",
    "    base_price_volume_cols = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
    "    feature_columns = [col for col in processed_data.columns if col not in base_price_volume_cols + ['target']]\n",
    "    \n",
    "    X = processed_data[feature_columns]\n",
    "    y = processed_data['target']\n",
    "    \n",
    "    print(f\"\\nNumber of features selected: {len(X.columns)}\")\n",
    "    # print(\"Selected features:\", X.columns.tolist())\n",
    "    print(f\"Original shape before NaN drop: X: {X.shape}, y: {y.shape}\")\n",
    "    \n",
    "    # Crucial step: Drop rows with any NaN values (in features or target)\n",
    "    # Indicators, rolling features, lag features, and target creation can all introduce NaNs.\n",
    "    combined_for_cleaning = X.assign(target=y)\n",
    "    cleaned_data = combined_for_cleaning.dropna()\n",
    "    \n",
    "    X_cleaned = cleaned_data[feature_columns]\n",
    "    y_cleaned = cleaned_data['target']\n",
    "    \n",
    "    print(f\"Shape after dropping NaNs: X_cleaned: {X_cleaned.shape}, y_cleaned: {y_cleaned.shape}\")\n",
    "    \n",
    "    if X_cleaned.empty or y_cleaned.empty:\n",
    "        print(\"\\nError: No data left after NaN removal. Consider:\")\n",
    "        print(\"- Using a longer date range for data download.\")\n",
    "        print(\"- Reducing window sizes for rolling features or number of lag periods.\")\n",
    "        print(\"- Using fillna(0) or other imputation for some features (though this might impact model quality).\")\n",
    "    else:\n",
    "        print(\"\\nFeatures (X_cleaned head) after NaN drop:\")\n",
    "        print(X_cleaned.head())\n",
    "        print(\"\\nTarget (y_cleaned head) after NaN drop:\")\n",
    "        print(y_cleaned.head())\n",
    "else:\n",
    "    print(\"Skipping feature/target selection as processed_data is not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Split Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X_cleaned' in locals() and not X_cleaned.empty:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_cleaned, y_cleaned, \n",
    "        test_size=TEST_SIZE, \n",
    "        shuffle=False, # Crucial for time-series data to prevent lookahead bias in validation\n",
    "        random_state=RANDOM_STATE # Ensures reproducibility of the split itself\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTraining set size: X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "    print(f\"Testing set size: X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "else:\n",
    "    print(\"\\nSkipping train-test split as no cleaned data is available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X_train' in locals() and not X_train.empty:\n",
    "    model = xgb.XGBClassifier(\n",
    "        objective='binary:logistic', # For binary classification (significant move vs. no significant move)\n",
    "        n_estimators=100,          # Number of trees (can be tuned)\n",
    "        learning_rate=0.1,         # Learning rate (can be tuned)\n",
    "        max_depth=3,               # Maximum depth of a tree (can be tuned)\n",
    "        use_label_encoder=False,   # Suppress warning, as labels are already 0/1 integers\n",
    "        eval_metric='logloss'      # Evaluation metric for early stopping or monitoring (can be 'auc', 'error', etc.)\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"\\nXGBoost model trained.\")\n",
    "else:\n",
    "    print(\"\\nSkipping model training as no training data is available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'model' in locals() and 'X_test' in locals() and not X_test.empty:\n",
    "    y_pred = model.predict(X_test) # Class predictions (0 or 1)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1] # Probabilities for the positive class (class 1)\n",
    "    \n",
    "    print(\"\\nPredictions made on the test set.\")\n",
    "    print(\"Sample class predictions (y_pred - first 10):\")\n",
    "    print(y_pred[:10])\n",
    "    print(\"\\nSample predicted probabilities for class 1 (y_pred_proba - first 10):\")\n",
    "    print(y_pred_proba[:10])\n",
    "else:\n",
    "    print(\"\\nSkipping predictions as model or test data is not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate Model\n",
    "\n",
    "Performance might vary with the new features. Feature selection and hyperparameter tuning would be the next steps to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'y_test' in locals() and 'y_pred' in locals() and 'y_pred_proba' in locals():\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, zero_division=0)\n",
    "    \n",
    "    print(f\"\\nAccuracy with new features: {accuracy:.4f}\")\n",
    "    print(\"\\nClassification Report with new features:\")\n",
    "    print(report)\n",
    "    \n",
    "    print(\"\\nTest Set Class Distribution (y_test):\")\n",
    "    print(y_test.value_counts(normalize=True))\n",
    "    print(\"\\nPredicted Class Distribution (y_pred from model with new features):\")\n",
    "    print(pd.Series(y_pred).value_counts(normalize=True))\n",
    "    \n",
    "    # --- ROC Curve and AUC Score ---\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve with New Features')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"AUC Score with new features: {roc_auc:.4f}\")\n",
    "    \n",
    "    # --- Confusion Matrix ---\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(7, 7))\n",
    "    disp.plot(ax=ax, cmap=plt.cm.Blues)\n",
    "    ax.set_title('Confusion Matrix with New Features')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nConfusion Matrix values (with new features):\")\n",
    "    print(f\"True Negatives (TN): {cm[0, 0]}\")\n",
    "    print(f\"False Positives (FP): {cm[0, 1]}\")\n",
    "    print(f\"False Negatives (FN): {cm[1, 0]}\")\n",
    "    print(f\"True Positives (TP): {cm[1, 1]}\")\n",
    "else:\n",
    "    print(\"\\nSkipping model evaluation as test results are not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the ROC Curve and AUC Score\n",
    "\n",
    "The **Receiver Operating Characteristic (ROC) Curve** visualizes the trade-off between the True Positive Rate (TPR, also known as sensitivity or recall) and the False Positive Rate (FPR, also known as 1-specificity) at various classification thresholds.\n",
    "- **True Positive Rate (TPR)**: Proportion of actual positive cases (significant price moves) that are correctly identified by the model.\n",
    "- **False Positive Rate (FPR)**: Proportion of actual negative cases (no significant price moves) that are incorrectly identified as positive by the model.\n",
    "\n",
    "**AUC (Area Under the Curve)**:\n",
    "- An AUC of **1.0** represents a perfect classifier.\n",
    "- An AUC of **0.5** represents a classifier with no discriminative ability (equivalent to random guessing), depicted by the dashed diagonal line.\n",
    "- An AUC **between 0.5 and 1.0** indicates the model has some ability to distinguish between the positive and negative classes. The closer to 1.0, the better the model's performance.\n",
    "- An AUC **less than 0.5** would suggest the model is performing worse than random (e.g., consistently misclassifying).\n",
    "\n",
    "A higher AUC generally indicates a better model. The shape of the curve also matters: a curve that bows further towards the top-left corner is better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the Confusion Matrix\n",
    "\n",
    "The **Confusion Matrix** provides a detailed breakdown of the model's predictions versus the actual classes.\n",
    "\n",
    "For our binary classification problem (predicting significant price movement vs. no significant price movement):\n",
    "- **True Negatives (TN)** (Top-Left): The number of instances where the model correctly predicted **no significant price move**, and there was indeed no significant price move.\n",
    "- **False Positives (FP)** (Top-Right): The number of instances where the model incorrectly predicted a **significant price move**, but there was actually no significant price move. This is a **Type I error**.\n",
    "  - *Implication*: May lead to unnecessary caution or missed opportunities if we act based on a predicted move that doesn't happen.\n",
    "- **False Negatives (FN)** (Bottom-Left): The number of instances where the model incorrectly predicted **no significant price move**, but there was actually a significant price move. This is a **Type II error**.\n",
    "  - *Implication*: Potentially more costly, as the model fails to identify a significant event.\n",
    "- **True Positives (TP)** (Bottom-Right): The number of instances where the model correctly predicted a **significant price move**, and there was indeed a significant price move.\n",
    "\n",
    "**Key metrics derived from the Confusion Matrix (often in the Classification Report):**\n",
    "- **Accuracy**: `(TP + TN) / (TP + TN + FP + FN)` - Overall correctness.\n",
    "- **Precision (for class 1 - significant move)**: `TP / (TP + FP)` - Of all predictions of a significant move, how many were correct? High precision means low FP rate for that class.\n",
    "- **Recall (Sensitivity, TPR, for class 1 - significant move)**: `TP / (TP + FN)` - Of all actual significant moves, how many did the model identify? High recall means low FN rate for that class.\n",
    "- **F1-Score (for class 1)**: `2 * (Precision * Recall) / (Precision + Recall)` - The harmonic mean of Precision and Recall, useful for imbalanced classes.\n",
    "\n",
    "Understanding these components helps in diagnosing the model's strengths and weaknesses, especially in identifying where it makes errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Importance (Optional)\n",
    "\n",
    "Feature importance will likely change with the new set of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'model' in locals() and 'X_cleaned' in locals() and not X_cleaned.empty:\n",
    "    feature_importances = pd.Series(model.feature_importances_, index=X_cleaned.columns)\n",
    "    feature_importances = feature_importances.sort_values(ascending=False)\n",
    "    \n",
    "    print(\"\\nFeature Importances (with new features):\")\n",
    "    print(feature_importances.head(20)) # Print top 20 features\n",
    "    \n",
    "    plt.figure(figsize=(12, 10)) # Adjusted size for potentially many features\n",
    "    feature_importances.head(30).plot(kind='bar') # Plot top 30 for readability\n",
    "    plt.title('Top 30 Feature Importances for XGBoost Model (with New Features)')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\nSkipping feature importance calculation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Backtesting with `simple_backtest`\n",
    "\n",
    "The backtesting results will also be affected by the new features influencing the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.backtesting import simple_backtest\n",
    "\n",
    "if 'model' in locals() and \\ \n",
    "   'X_test' in locals() and not X_test.empty and \\ \n",
    "   'processed_data' in locals() and processed_data is not None and \\ \n",
    "   'y_pred' in locals() and \\ \n",
    "   'FUTURE_DAYS_TARGET' in locals():\n",
    "\n",
    "    y_pred_series_on_test_index = pd.Series(y_pred, index=X_test.index)\n",
    "    \n",
    "    # Use 'Close' prices from 'processed_data' aligned with X_test's index for backtesting\n",
    "    # This ensures we are using the price data that corresponds to the features used for prediction.\n",
    "    backtest_price_data = processed_data['Close'].loc[X_test.index].copy()\n",
    "    \n",
    "    signals_for_backtest = pd.Series(0, index=X_test.index, dtype=int)\n",
    "    \n",
    "    for date_index, model_prediction_signal in y_pred_series_on_test_index.items():\n",
    "        if model_prediction_signal == 1:\n",
    "            current_price_for_signal_eval = processed_data['Close'].loc[date_index]\n",
    "            try:\n",
    "                current_date_location_in_processed_data = processed_data.index.get_loc(date_index)\n",
    "                future_date_location_in_processed_data = current_date_location_in_processed_data + FUTURE_DAYS_TARGET\n",
    "                \n",
    "                if future_date_location_in_processed_data < len(processed_data.index):\n",
    "                    future_price_actual_date_index = processed_data.index[future_date_location_in_processed_data]\n",
    "                    future_price_for_signal_eval = processed_data['Close'].loc[future_price_actual_date_index]\n",
    "                    \n",
    "                    if future_price_for_signal_eval > current_price_for_signal_eval:\n",
    "                        signals_for_backtest.loc[date_index] = 1\n",
    "                    elif future_price_for_signal_eval < current_price_for_signal_eval:\n",
    "                        signals_for_backtest.loc[date_index] = -1\n",
    "            except KeyError:\n",
    "                print(f\"Warning: Index {date_index} from X_test not found in processed_data.index during signal generation.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error during signal generation for index {date_index}: {e}\")\n",
    "\n",
    "    print(\"\\nValue counts for generated 'perfect foresight' signals (with new features):\")\n",
    "    print(signals_for_backtest.value_counts())\n",
    "    \n",
    "    initial_capital_backtest = 10000.0\n",
    "    leverage_backtest = 1.0\n",
    "    \n",
    "    print(f\"\\nRunning backtest with initial capital: ${initial_capital_backtest:,.2f}, leverage: {leverage_backtest}\")\n",
    "    \n",
    "    if not backtest_price_data.index.equals(signals_for_backtest.index):\n",
    "        print(\"CRITICAL ERROR: Price data and signal indices for backtest do not match!\")\n",
    "    elif backtest_price_data.isnull().any() or signals_for_backtest.isnull().any():\n",
    "        print(\"Warning: NaNs found in backtest price data or signals!\")\n",
    "    elif backtest_price_data.empty or signals_for_backtest.empty:\n",
    "        print(\"Error: Backtest price data or signals are empty.\")\n",
    "    else:\n",
    "        equity_curve, performance_metrics = simple_backtest(\n",
    "            price_data=backtest_price_data, \n",
    "            signals=signals_for_backtest, \n",
    "            initial_capital=initial_capital_backtest,\n",
    "            leverage=leverage_backtest\n",
    "        )\n",
    "        \n",
    "        print(\"\\nBacktest Performance Metrics (with new features):\")\n",
    "        if performance_metrics:\n",
    "            for metric, value in performance_metrics.items():\n",
    "                print(f\"{metric}: {value:.2f}\")\n",
    "            \n",
    "            print(\"\\nPlotting Equity Curve (with new features)...\")\n",
    "            plt.figure(figsize=(12, 7))\n",
    "            equity_curve.plot()\n",
    "            plt.title(f'Equity Curve for {TICKER} (Perfect Foresight Signals, New Features)')\n",
    "            plt.xlabel('Date')\n",
    "            plt.ylabel('Portfolio Value ($)')\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Backtest performance metrics dictionary is empty.\")\n",
    "else:\n",
    "    print(\"\\nSkipping backtesting. Essential variables not available.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
