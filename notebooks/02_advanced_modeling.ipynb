{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Modeling: LSTM, LightGBM, CatBoost, Prophet, CNN-LSTM, Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit \n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src import config\n",
    "from src.data_management import download_stock_data\n",
    "from src.feature_engineering import add_technical_indicators, add_rolling_lag_features, create_target_variable\n",
    "from src.modeling import (\n",
    "    train_lstm, predict_lstm, \n",
    "    train_lightgbm, predict_lightgbm,\n",
    "    train_catboost, predict_catboost,\n",
    "    train_prophet, predict_prophet,\n",
    "    train_cnnlstm, predict_cnnlstm, # Added CNN-LSTM\n",
    "    train_transformer, predict_transformer # Added Transformer\n",
    ")\n",
    "from src.utils import save_model, load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TICKER = config.DEFAULT_TICKERS[0] if config.DEFAULT_TICKERS else 'AAPL'\n",
    "START_DATE = '2018-01-01' \n",
    "END_DATE = config.DEFAULT_END_DATE\n",
    "INTERVAL = '1d'\n",
    "\n",
    "FUTURE_DAYS_TARGET = 5\n",
    "PERCENT_CHANGE_THRESHOLD = 0.03\n",
    "\n",
    "ROLLING_WINDOWS = [5, 10, 20, 60]\n",
    "LAG_PERIODS = [1, 2, 3, 5, 10]\n",
    "KEY_LAG_INDICATORS = ['RSI_14', 'MACD', 'ATR_14', 'Stoch_k', 'ADX_14']\n",
    "\n",
    "SEQUENCE_LENGTH = 20 \n",
    "N_SPLITS_TIMESERIES = 5\n",
    "\n",
    "FIT_PARAMS_DEFAULT = {'epochs': 50, 'batch_size': 32, 'validation_split': 0.1, 'verbose': 0}\n",
    "\n",
    "LSTM_TRAIN_PARAMS = {\n",
    "    'lstm_params': {'lstm_units': 50, 'dropout_rate': 0.2, 'dense_units_factor': 0.5},\n",
    "    'fit_params': FIT_PARAMS_DEFAULT\n",
    "}\n",
    "CNNLSTM_TRAIN_PARAMS = {\n",
    "    'cnnlstm_params': {'filters': 64, 'kernel_size': 3, 'pool_size': 2, 'lstm_units': 50, 'dropout_rate': 0.2, 'dense_units_factor': 0.5},\n",
    "    'fit_params': FIT_PARAMS_DEFAULT\n",
    "}\n",
    "TRANSFORMER_TRAIN_PARAMS = {\n",
    "    'transformer_params': {'embed_dim': 64, 'num_heads': 2, 'ff_dim': 32, 'num_transformer_blocks': 1, 'dropout_rate': 0.1},\n",
    "    'fit_params': FIT_PARAMS_DEFAULT\n",
    "}\n",
    "\n",
    "LGBM_PARAMS = {\n",
    "    'objective': 'binary', 'metric': 'binary_logloss', 'n_estimators': 200,\n",
    "    'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1,\n",
    "    'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'verbose': -1\n",
    "}\n",
    "CATBOOST_PARAMS = {\n",
    "    'iterations': 200, 'learning_rate': 0.05, 'depth': 6,\n",
    "    'loss_function': 'Logloss', 'eval_metric': 'AUC', 'verbose': 0,\n",
    "    'early_stopping_rounds': 10\n",
    "}\n",
    "PROPHET_FORECAST_PERIOD = 90 \n",
    "\n",
    "LSTM_MODEL_FILENAME = f\"lstm_model_{TICKER.lower()}.h5\"\n",
    "CNNLSTM_MODEL_FILENAME = f\"cnnlstm_model_{TICKER.lower()}.h5\"\n",
    "TRANSFORMER_MODEL_FILENAME = f\"transformer_model_{TICKER.lower()}.h5\"\n",
    "LGBM_MODEL_FILENAME = f\"lgbm_model_{TICKER.lower()}.txt\"\n",
    "CATBOOST_MODEL_FILENAME = f\"catboost_model_{TICKER.lower()}.cbm\"\n",
    "PROPHET_MODEL_FILENAME = f\"prophet_model_{TICKER.lower()}.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Engineer Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_dl = download_stock_data([TICKER], START_DATE, END_DATE, INTERVAL)\n",
    "if raw_data_dl is None: raise ValueError(f\"Failed to download data for {TICKER}.\")\n",
    "processed_df = raw_data_dl.droplevel(0, axis=1) if isinstance(raw_data_dl.columns, pd.MultiIndex) else raw_data_dl.copy()\n",
    "\n",
    "data_with_ti = add_technical_indicators(processed_df, fillna=True)\n",
    "data_with_roll_lag = add_rolling_lag_features(data_with_ti, windows=ROLLING_WINDOWS, lags=LAG_PERIODS, lag_indicators=KEY_LAG_INDICATORS)\n",
    "final_processed_data = create_target_variable(data_with_roll_lag, future_days=FUTURE_DAYS_TARGET, percent_change_threshold=PERCENT_CHANGE_THRESHOLD)\n",
    "print(f\"Final processed data shape: {final_processed_data.shape}\")\n",
    "\n",
    "base_cols = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
    "feature_cols = [col for col in final_processed_data.columns if col not in base_cols + ['target']]\n",
    "X_unproc = final_processed_data[feature_cols]\n",
    "y_unproc = final_processed_data['target']\n",
    "ohlcv_unproc = final_processed_data[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
    "\n",
    "model_input_data = X_unproc.assign(target=y_unproc)\n",
    "cleaned_indices = model_input_data.dropna().index\n",
    "X_full_cleaned = X_unproc.loc[cleaned_indices]\n",
    "y_full_cleaned = y_unproc.loc[cleaned_indices]\n",
    "ohlcv_full_cleaned = ohlcv_unproc.loc[cleaned_indices]\n",
    "print(f\"Shape after NaN drop: X: {X_full_cleaned.shape}, y: {y_full_cleaned.shape}, OHLCV: {ohlcv_full_cleaned.shape}\")\n",
    "if X_full_cleaned.empty: raise ValueError(\"No data after NaN drop.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Split Data for Time Series Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=N_SPLITS_TIMESERIES)\n",
    "train_idx, test_idx = None, None\n",
    "for i, (idx_train, idx_test) in enumerate(tscv.split(X_full_cleaned)):\n",
    "    if i == N_SPLITS_TIMESERIES - 1: train_idx, test_idx = idx_train, idx_test\n",
    "\n",
    "X_train, X_test = X_full_cleaned.iloc[train_idx], X_full_cleaned.iloc[test_idx]\n",
    "y_train, y_test = y_full_cleaned.iloc[train_idx], y_full_cleaned.iloc[test_idx]\n",
    "ohlcv_train, ohlcv_test = ohlcv_full_cleaned.iloc[train_idx], ohlcv_full_cleaned.iloc[test_idx]\n",
    "\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Training LSTM Model ---\")\n",
    "try:\n",
    "    lstm_model, lstm_scaler = train_lstm(\n",
    "        X_train_df=X_train.copy(), y_train_series=y_train.copy(),\n",
    "        sequence_length=SEQUENCE_LENGTH, **LSTM_TRAIN_PARAMS\n",
    "    )\n",
    "    save_model(lstm_model, LSTM_MODEL_FILENAME, models_dir=config.MODELS_DIR)\n",
    "    save_model(lstm_scaler, f\"lstm_scaler_{TICKER.lower()}.pkl\", models_dir=config.MODELS_DIR)\n",
    "    y_pred_lstm_c, y_pred_lstm_p = predict_lstm(lstm_model, X_test.copy(), lstm_scaler, SEQUENCE_LENGTH)\n",
    "    if len(y_pred_lstm_c) > 0:\n",
    "        y_test_lstm_eval = y_test.iloc[len(y_test) - len(y_pred_lstm_c):]\n",
    "        print(\"\\nLSTM Evaluation:\")\n",
    "        print(f\"Accuracy: {accuracy_score(y_test_lstm_eval, y_pred_lstm_c):.4f}\")\n",
    "    else: print(\"No LSTM predictions to evaluate due to sequence length vs test data size.\")\n",
    "except ValueError as e: print(f\"LSTM Error: {e}\")\n",
    "except Exception as e: print(f\"An unexpected error occurred with LSTM: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. LightGBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Training LightGBM Model ---\")\n",
    "try:\n",
    "    lgbm_model = train_lightgbm(X_train, y_train, params=LGBM_PARAMS)\n",
    "    save_model(lgbm_model, LGBM_MODEL_FILENAME, models_dir=config.MODELS_DIR)\n",
    "    y_pred_lgbm_c, y_pred_lgbm_p = predict_lightgbm(lgbm_model, X_test)\n",
    "    print(\"\\nLightGBM Evaluation:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred_lgbm_c):.4f}\")\n",
    "except Exception as e: print(f\"An unexpected error occurred with LightGBM: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. CatBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Training CatBoost Model ---\")\n",
    "try:\n",
    "    catboost_model = train_catboost(X_train, y_train, params=CATBOOST_PARAMS)\n",
    "    save_model(catboost_model, CATBOOST_MODEL_FILENAME, models_dir=config.MODELS_DIR)\n",
    "    y_pred_cat_c, y_pred_cat_p = predict_catboost(catboost_model, X_test)\n",
    "    print(\"\\nCatBoost Evaluation:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred_cat_c):.4f}\")\n",
    "except Exception as e: print(f\"An unexpected error occurred with CatBoost: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. CNN-LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Training CNN-LSTM Model ---\")\n",
    "CNNLSTM_MODEL_FILENAME = f\"cnnlstm_model_{TICKER.lower()}.h5\"\n",
    "try:\n",
    "    cnnlstm_model, cnnlstm_scaler = train_cnnlstm(\n",
    "        X_train_df=X_train.copy(), y_train_series=y_train.copy(),\n",
    "        sequence_length=SEQUENCE_LENGTH, **CNNLSTM_TRAIN_PARAMS\n",
    "    )\n",
    "    save_model(cnnlstm_model, CNNLSTM_MODEL_FILENAME, models_dir=config.MODELS_DIR)\n",
    "    save_model(cnnlstm_scaler, f\"cnnlstm_scaler_{TICKER.lower()}.pkl\", models_dir=config.MODELS_DIR)\n",
    "    \n",
    "    y_pred_cnnlstm_c, y_pred_cnnlstm_p = predict_cnnlstm(cnnlstm_model, X_test.copy(), cnnlstm_scaler, SEQUENCE_LENGTH)\n",
    "    if len(y_pred_cnnlstm_c) > 0:\n",
    "        y_test_cnnlstm_eval = y_test.iloc[len(y_test) - len(y_pred_cnnlstm_c):]\n",
    "        print(\"\\nCNN-LSTM Evaluation:\")\n",
    "        print(f\"Accuracy: {accuracy_score(y_test_cnnlstm_eval, y_pred_cnnlstm_c):.4f}\")\n",
    "        # print(classification_report(y_test_cnnlstm_eval, y_pred_cnnlstm_c, zero_division=0))\n",
    "    else: print(\"No CNN-LSTM predictions to evaluate.\")\n",
    "except ValueError as e: print(f\"CNN-LSTM Error: {e}\")\n",
    "except Exception as e: print(f\"An unexpected error occurred with CNN-LSTM: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Training Transformer Model ---\")\n",
    "TRANSFORMER_MODEL_FILENAME = f\"transformer_model_{TICKER.lower()}.h5\"\n",
    "TRANSFORMER_TRAIN_PARAMS['transformer_params']['embed_dim'] = X_train.shape[1] # Ensure embed_dim matches num_features\n",
    "try:\n",
    "    transformer_model, transformer_scaler = train_transformer(\n",
    "        X_train_df=X_train.copy(), y_train_series=y_train.copy(),\n",
    "        sequence_length=SEQUENCE_LENGTH, **TRANSFORMER_TRAIN_PARAMS\n",
    "    )\n",
    "    save_model(transformer_model, TRANSFORMER_MODEL_FILENAME, models_dir=config.MODELS_DIR)\n",
    "    save_model(transformer_scaler, f\"transformer_scaler_{TICKER.lower()}.pkl\", models_dir=config.MODELS_DIR)\n",
    "    \n",
    "    y_pred_transformer_c, y_pred_transformer_p = predict_transformer(transformer_model, X_test.copy(), transformer_scaler, SEQUENCE_LENGTH)\n",
    "    if len(y_pred_transformer_c) > 0:\n",
    "        y_test_transformer_eval = y_test.iloc[len(y_test) - len(y_pred_transformer_c):]\n",
    "        print(\"\\nTransformer Evaluation:\")\n",
    "        print(f\"Accuracy: {accuracy_score(y_test_transformer_eval, y_pred_transformer_c):.4f}\")\n",
    "        # print(classification_report(y_test_transformer_eval, y_pred_transformer_c, zero_division=0))\n",
    "    else: print(\"No Transformer predictions to evaluate.\")\n",
    "except ValueError as e: print(f\"Transformer Error: {e}\")\n",
    "except Exception as e: print(f\"An unexpected error occurred with Transformer: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Prophet Model (as before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Training Prophet Model ---\")\n",
    "prophet_train_df = ohlcv_train[['Close']].reset_index()\n",
    "prophet_train_df.rename(columns={'Date': 'ds', 'Close': 'y'}, inplace=True)\n",
    "if 'ds' not in prophet_train_df.columns and isinstance(prophet_train_df.index, pd.DatetimeIndex):\n",
    "    prophet_train_df.index.name = 'ds'\n",
    "    prophet_train_df = prophet_train_df.reset_index()\n",
    "\n",
    "if 'ds' in prophet_train_df.columns and 'y' in prophet_train_df.columns:\n",
    "    try:\n",
    "        prophet_model = train_prophet(prophet_train_df)\n",
    "        save_model(prophet_model, PROPHET_MODEL_FILENAME, models_dir=config.MODELS_DIR)\n",
    "        print(\"Prophet model trained and saved.\")\n",
    "        future_periods_for_test = len(ohlcv_test)\n",
    "        prophet_forecast = predict_prophet(prophet_model, periods=future_periods_for_test, freq='B')\n",
    "        # Prophet plotting and signal evaluation (simplified for brevity)\n",
    "        # fig1 = prophet_model.plot(prophet_forecast)\n",
    "        # plt.show()\n",
    "    except Exception as e: print(f\"Prophet processing error: {e}\")\n",
    "else: print(\"Prophet training data not prepared correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. (Placeholder) Optuna Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nOptuna setup would be here.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
