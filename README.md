<!-- README.md is auto-generated from docs/sections/*.md files by generate_readme.py -->
<!-- DO NOT EDIT THIS FILE DIRECTLY. Edit the section files or the script. -->

# Project Title: Quantitative Leverage Opportunity Predictor (QLOP)

**Brief Description:** QLOP is an advanced stock analysis and prediction tool designed to identify potential leverage opportunities in the stock market. It incorporates data ingestion, feature engineering, model training, evaluation, backtesting, and provides insights through a GUI, CLI, and eventually an API.


---

## Key Features

- **Modular Design:** Core components (data, features, models, API) are separated for clarity and maintainability.
- **CLI Interface:** Provides command-line access to pipeline operations (`main.py`).
- **GUI Interface:** Streamlit-based GUI (`gui.py`) for interactive data analysis and model training.
- **Pydantic Configuration:** Type-safe configuration management using Pydantic models (`src/config_models.py`).
- **Versatile Modeling:** Supports XGBoost, LightGBM, CatBoost, LSTM, CNN-LSTM, and Transformer models.
- **Advanced Backtesting:** Includes stubs for walk-forward and dynamic rolling window evaluations.
- **Metadata Tracking:** Generates metadata for trained models (`src/metadata_utils.py`).
- **Sentiment Analysis:** Integrates news sentiment analysis using Hugging Face transformers.
- **Fundamental Data:** Incorporates fundamental stock data.
- **Hyperparameter Tuning:** Optuna integration for optimizing model parameters (`src/tuner.py`).
- **Dockerization Support:** Includes a `Dockerfile` for containerized deployment.
- **CI/CD Readiness:** Basic testing structure (`tests/`) and integrity checks (`check_pipeline_integrity.py`).
- **Auto-generated Documentation:** This README is auto-generated from modular sections.

(More features to be listed as developed)


---

## Setup and Installation

Detailed setup instructions can be found in [docs/setup/](./docs/setup/).

**Quick Start:**

1.  Clone the repository:
    ```bash
    git clone <repository_url>
    cd <repository_name>
    ```
2.  Install dependencies:
    ```bash
    pip install -r requirements.txt
    ```
3.  (Optional) Set up API keys in `.env` or environment variables (see [docs/setup/environment_variables.md](./docs/setup/environment_variables.md) - *to be created*).

For GPU support and OS-specific instructions, refer to:
- [OS Specific Setup](./docs/setup/os_specific_setup.md)
- [GPU/CPU Support](./docs/setup/gpu_cpu_support.md)


---

## GUI Usage

The application provides a user-friendly Graphical User Interface (GUI) built with Streamlit.

To launch the GUI:
```bash
streamlit run gui.py
```
The GUI allows for:
- Interactive data loading and visualization.
- Selection of features for engineering.
- Training and evaluation of various models.
- Placeholder for backtesting visualization.

For detailed GUI workflows, see [docs/workflows/](./docs/workflows/).
(Currently, GUI operations are refactored to call the CLI. Full interactivity for data display post-CLI calls is pending further development).


---

## CLI Usage

The project includes a Command Line Interface (CLI) built with `click` for interacting with the pipeline.

To see available commands:
```bash
python main.py --help
```

**Key Commands:**

-   `python main.py load-data --config <path_to_load_config.json>`
-   `python main.py engineer-features --config <path_to_feature_config.json>`
-   `python main.py train-model --config <path_to_train_config.json>`
-   `python main.py evaluate --config <path_to_eval_config.json>`
-   `python main.py backtest --config <path_to_backtest_config.json>`
-   `python main.py export --config <path_to_export_config.json>`


    - `python main.py --help`
    - `python main.py load-data --config <config_path>`
    - `python main.py engineer-features --config <config_path>`
    - `python main.py train-model --config <config_path>`
    - `python main.py evaluate --config <config_path>`
    - `python main.py backtest --config <config_path>`
    - `python main.py export --config <config_path>`
    
(CLI command list will be auto-generated here in the future)
<!-- END_AUTOGEN:CLI_COMMANDS_LIST -->

For detailed CLI workflows and configuration options, see [docs/workflows/](./docs/workflows/). The configuration for each command is defined using Pydantic models in `src/config_models.py`.


---

## API Usage

The project aims to expose its functionalities via a RESTful API (or gRPC).

**Current Status:**
- API controllers are defined in `api/controllers.py` (currently stubs).
- API data models (request/response schemas) will be defined in `api/models.py` using Pydantic.
- The API will be served using a framework like FastAPI or Flask.

For detailed API endpoint documentation, see [docs/modules/api_reference.md](./docs/modules/api_reference.md) (once implemented).

**Example (Conceptual):**
```bash
# Example: Train a model via API
# POST /api/v1/train
# Body: { "model_type": "XGBoost", "data_config_ref": "...", "feature_config_ref": "..." }
```


---

## Examples

Find detailed examples and usage scenarios in the [workflows documentation](./docs/workflows/).

- **Example 1: Training an XGBoost Model**
  - See [docs/workflows/workflow_example_1.md](./docs/workflows/workflow_example_1.md) (to be created) for a step-by-step guide on training an XGBoost model using the CLI, including configuration.

<!-- AUTOGEN:EXAMPLES_LIST -->
(More examples will be listed here as they are documented.)
<!-- END_AUTOGEN:EXAMPLES_LIST -->


---

## Architecture Overview

This project follows a modular architecture designed for scalability and maintainability.

-   **`src/`**: Contains the core pipeline logic:
    -   `data_management.py`: Data loading and preprocessing.
    -   `feature_engineering.py`: Feature creation and selection.
    -   `modeling.py`: Model definitions, training, and prediction functions.
    -   `evaluation.py`: Model evaluation metrics and plots.
    -   `backtesting.py`: Backtesting strategies and execution.
    -   `tuner.py`: Hyperparameter tuning using Optuna.
    -   `config_models.py`: Pydantic models for configuration validation.
    -   `metadata_utils.py`: Utilities for generating model metadata.
    -   `utils.py`: General utility functions, including logging and model saving/loading.
    -   `sentiment_analysis.py`: News sentiment fetching and analysis.
    -   `fundamental_data.py`: Fetching and processing fundamental stock data.
-   **`main.py`**: CLI entry point using `click`.
-   **`gui.py`**: Streamlit GUI application.
-   **`api/`**: For the future REST/gRPC API:
    -   `controllers.py`: API logic (currently stubs).
    -   `models.py`: API request/response Pydantic models (placeholders).
-   **`config/`**: JSON configuration files for different environments (dev, test, prod).
-   **`models/`**: Default directory for saved trained models and their metadata.
-   **`data/`**: For raw, processed, and feature data.
-   **`notebooks/`**: Jupyter notebooks for experimentation.
-   **`tests/`**: Unit and integration tests.
-   **`docs/`**: Documentation, including these auto-generated README sections.

(A more detailed architecture diagram will be added here.)


---

## Roadmap

-   **Q3 2024:**
    -   Implement core logic for all `main.py` CLI subcommands.
    -   Full integration of Pydantic configurations.
    -   Basic API endpoint implementations (e.g., for `load-data`, `train-model`).
-   **Q4 2024:**
    -   Complete advanced backtesting features (`walk_forward_test`, `dynamic_rolling_window_evaluation`).
    -   Implement MLflow tracking for experiments and models.
    -   Refine GUI for better interactivity post-CLI calls.
-   **Future:**
    -   Expand feature engineering options.
    -   Add more model types.
    -   Cloud deployment options.
    -   Real-time prediction capabilities.

(This roadmap is indicative and subject to change.)


---

## Changelog

Refer to [CHANGELOG.md](./CHANGELOG.md) for detailed changes in each version.

CHANGELOG.md not found.
(A summary of recent changes might be auto-generated here in the future.)
<!-- END_AUTOGEN:CHANGELOG_SUMMARY -->


---

## Contributing

Contributions are welcome! Please follow these guidelines:

1.  Fork the repository.
2.  Create a new branch for your feature or bug fix.
3.  Ensure your code adheres to project standards (linting, tests).
4.  Submit a pull request with a clear description of your changes.

(More detailed contribution guidelines will be added, including code style, testing requirements, etc.)


---

## License

This project is licensed under the MIT License. See the [LICENSE](./LICENSE) file for details.
(Note: A `LICENSE` file should be created in the root directory with the MIT License text if one doesn't exist.)
